{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa82d272",
   "metadata": {},
   "source": [
    "### Q1. You receive a dataset containing categorical variables with high cardinality (e.g., “City” with over 10,000 unique entries). Which of the following preprocessing strategies is most appropriate for a large-scale machine learning pipeline to handle this issue efficiently?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641dd6ce",
   "metadata": {},
   "source": [
    "A. Apply one-hot encoding to all categorical features\n",
    "\n",
    "B. Convert categories to integer labels without normalization\n",
    "\n",
    "C. Use frequency or target encoding for the categorical variable\n",
    "\n",
    "D. Drop the feature entirely to reduce dimensionality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e406d2",
   "metadata": {},
   "source": [
    "### Q2. While cleaning a dataset, you find multiple missing values in numerical columns. If the missingness is determined to be Missing Not At Random (MNAR), what is the most statistically sound approach?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7511e7",
   "metadata": {},
   "source": [
    "A. Impute missing values using the column mean or median\n",
    "\n",
    "B. Drop all rows with missing values\n",
    "\n",
    "C. Introduce a binary indicator for missingness and model it explicitly\n",
    "\n",
    "D. Replace missing values with zeros to maintain dataset size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f592db",
   "metadata": {},
   "source": [
    "### Q3. In a time-series dataset with irregular timestamps, you decide to resample data at hourly intervals. Which preprocessing step ensures consistency in the feature space and prevents data leakage?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6428704e",
   "metadata": {},
   "source": [
    "A. Backward-fill all missing values with the next available observation\n",
    "\n",
    "B. Forward-fill missing values after aggregating at each interval\n",
    "\n",
    "C. Randomly assign values to missing timestamps for balance\n",
    "\n",
    "D. Use interpolation while maintaining chronological ordering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d000e877",
   "metadata": {},
   "source": [
    "### Q4. You’re working with a dataset that includes extreme outliers in multiple numerical features. Before applying PCA for dimensionality reduction, which data preprocessing technique is most critical to ensure reliable results?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d87644",
   "metadata": {},
   "source": [
    "A. Standardization (Z-score normalization)\n",
    "\n",
    "B. Min–Max scaling to [0, 1] range\n",
    "\n",
    "C. Robust scaling using median and IQR\n",
    "\n",
    "D. Log transformation of all numerical features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9197072",
   "metadata": {},
   "source": [
    "### Q5. You are integrating multiple datasets from different sources, each using different naming conventions and data types. Which step should be prioritized before feature engineering to ensure reliable merging and transformation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fc4e47",
   "metadata": {},
   "source": [
    "A. Perform normalization to scale numerical variables\n",
    "\n",
    "B. Convert all data to strings to simplify joining operations\n",
    "\n",
    "C. Standardize schema: align column names, data types, and key identifiers\n",
    "\n",
    "D. Apply feature selection to eliminate redundant variables"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
